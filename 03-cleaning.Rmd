# Chapter 3 Data transformation

We are working around three dataset in total, that is, titles.basics, title.crew, title.ratings. Therefore, it was very necessary to transformation the individual overall datasets by merging different datasets, adding new columns or removing the ones that were not needed or that had any NULL values.<br/><br/>

Below, we describe the transformations that we incorporated which were necessary to accomplish the results of different questions.<br/><br/>

```{r}
library(tidyverse)
library(patchwork)
library(reshape2)
library(dplyr)
library(ggplot2)
library(ggridges)
library(parcoords)
library(ggrepel)
```

## Transformations to study distribution trends in Adult v/s Non-Adult titles

<br/>This question basically addresses two objectives.<br/>
- The first part studies the trend of number of adult title releases with the change of time.<br/>
- The second part studies the proportion of votes distribution of adult versus non-adult titles over the given period of time.<br/>
For this question, we primarily use the title.basics and title.ratings dataset. Therefore, we will initially prepare a new auxiliary dataframe which contains transformed version of these datasets.<br/>

### Adult title releases trends

<br/> In this part of the first objective question we wish to observe that with progressing years, did the film industry started making more adults, or less adults, or was the number of releases constant. The following steps show a detailed explanation on how we transformed the data step by step:<br/>
- Among all the columns available in the title.basics dataset, we are only interested in using the 'startYear' and 'isAdult' columns to achieve the first part of the first objective question. Thus, we dropped the other available columns in the data which were unnecessary for our exploration, likewise, 'primaryTitle', 'originalTitle', 'endYear', 'runtimeMinutes' and formed a new auxiliary dataframe named 'basics_ratings'.<br/>
- Further, as mentioned earlier, we need the necessary information('startYear' and 'isAdult') from title.basics, which basically is the basics_ratings dataframe, and title.ratings data combined in one auxiliary dataframe. So, we merge the title.ratings dataset with the basics_ratings dataframe and use to address both first and second part of the first objective question.<br/>
-Moreover, we analyzed that there were missing values in the 'isAdult' and 'startYear' columns. As we are going to explore that with the progress of year does the number of adult movies released had any trend or not, so we need to remove the start years values that have NULL. Also, we are summing up the total number of adult titles released per year, therefore, it is necessary to delete the rows that have NA values for isAdult. Thus, we dropped the rows which either contained NULL values for startYear or NULL values for isAdult.<br/>
- After cleaning the data by adding, removing and merging the columns, the next step is to group similar start years together and calculate the total number of adult titles that were released in that particular year. For this grouping operation to execute, we converted the datatype of both 'startYear ' and 'isAdult' columns to numeric. Once the datatype was transformed in the desired format, we grouped similar years together based on two different conditions:<br/>
  -Grouped same years and calculated the sum of the isAdult column which gave the total number of adult titles released in a particular year. We assigned this to a new temporary dataframe. <br/>
  -Grouped same years and counted the number of rows of the isAdult column which gave the total number    of titles released in a particular in a particular year irrespective of adult or non-adult. We        assigned this to another new temporary dataframe.<br/>
Finally, we merged the above two temporary dataframes into one by the grouped start years.<br/>
- As the last step, we calculated the proportion of the adult titles released per start year. This percent would then be used to plot it against their respective start years and study the trend.<br/><br/>


```{r}
drops <- c("primaryTitle","originalTitle","endYear", "runtimeMinutes")
basics_ratings <- basics[ , !(names(basics) %in% drops)]
```

```{r}
basics_ratings <- merge(basics_ratings, ratings, by="tconst")
basics_ratings
```

```{r}
basics_ratings_crew <- merge(basics_ratings, crew, by = "tconst")
basics_ratings_crew <- basics_ratings_crew[!is.na(basics_ratings_crew$directors) & !is.na(basics_ratings_crew$startYear), ]
basics_ratings_crew
```

```{r}
basics_ratings <- basics_ratings[!is.na(basics_ratings$isAdult), ]
basics_ratings$startYear <- as.numeric(basics_ratings$startYear)
basics_ratings$isAdult <- as.numeric(basics_ratings$isAdult)

basics_ratings <- basics_ratings %>% drop_na(isAdult)
basics_ratings <- basics_ratings %>% drop_na(startYear)
```

```{r}
basics_ratings$startYear <- as.numeric(basics_ratings$startYear)
basics_ratings$isAdult <- as.numeric(basics_ratings$isAdult)
b1 <- basics_ratings %>% group_by(startYear) %>% summarise(isAdult = sum(isAdult))
b2 <- basics_ratings %>% group_by(startYear) %>% summarise(cnt = n())
b_final <- merge(b1, b2, by="startYear")
b_final$adult_proportion <- (b_final$isAdult / b_final$cnt) * 100
```

### Ratings distribution of non-adult vs adult titles
```{r}
b_0 <- filter(basics_ratings, isAdult == 0)
b_1 <- filter(basics_ratings, isAdult == 1)

b_0_0 <- b_0 %>% group_by(startYear) %>% summarise(numVotes = sum(numVotes))
b_1_1 <- b_1 %>% group_by(startYear) %>% summarise(numVotes = sum(numVotes))

b_num_votes <- merge(b_0_0, b_1_1, by = 'startYear', all = TRUE)
b_num_votes[is.na(b_num_votes)] <- 0

b_num_votes$non_adult <- as.matrix(b_num_votes[2] / rowSums(b_num_votes[2:3])) * 100
b_num_votes$adult <- as.matrix(b_num_votes[3] / rowSums(b_num_votes[2:3])) * 100
```
<br/><br/>
In this part of the first objective question, we are basically studying that did the non-adult titles released more percentages of votes, or less percentages of votes, or same as compared to the votes received by the adult titles in particular year. The following steps explains the transformations that we followed:<br/>
- First, we filtered out the rows from the basics_ratings dataset that had information about the non-adult titles and stored them in a new temporary auxiliary dataframe. Similarily, we filtered out the rows from the basics_ratings dataset that had information about the adult titles and stored them in another new temporary auxiliary dataframe.<br/>
- Further, we merged the above two temporary dataframes together into one based on similar start years and calculated the sum of the number of votes that were received by non adult and adult titles respectively. These two sums were basically created as two different new columns.<br/>
- Next we merged the above two columns based on start year to form a new transformed dataframe. Moreover, while merging there was a case when there would be some years which were not present in non adult titles or vice versa. So, performed a detailed transformation that included the start years from both the columns and not just the common years. In this situation, the rows that would result in NA values for the number of votes were transformed to get replaced by 0.<br/>
- Finally, we calculated a new column 'non-adult' in the merged dataframe above that contained the proportion of titles that were non-adult type for the particular year. Similarly, we created another new column in the merged dataframe above that contained the proportion of titles that were adult type for that particular year. These two columns would be used to plot against the start year and study that among the total votes received per year, how much percentage of votes were for non-adult titles and how much were for adult.<br/>

## Transformations to study the distributions of genre
<br/><br/>
Our second objective question studies how different genres vary in terms of votes, title type, and ratings. We would like to know which genres tend to recieve the most attention and how the type of work has an affect on ratings even within the most popular genre. As the dataset is very large, we decided to subset the dataset based on works done by experience directors. We have defined experience as those directors who have completed at least 20 works. By subsetting this way, we are also looking at top works within the dataset. The limitation with subsetting in this manner is that we may be losing data on works created by directors who are experienced but do not show up in the dataset at least 20 times.

```{r}
expDirecs <- basics_ratings_crew %>%
  group_by(directors) %>%
  count()
expDirecs2 <- expDirecs[which(expDirecs$n >= 20), ]
expDirecs2
```


```{r}
# 2(A)
byGenre1 <- subset(basics_ratings_crew, basics_ratings_crew$directors %in% expDirecs2$directors)

groupedGenre <- byGenre1 %>%
  group_by(titleType, genres) %>%
  summarize(weightedRating = sum(averageRating * numVotes) / sum(numVotes), totalVotes = sum(numVotes))

groupedGenre_complete <- na.omit(groupedGenre)
groupedGenre_complete
```


```{r}
genres <- subset(groupedGenre_complete, select = c(genres))
genres <- genres[!grepl(",", genres[["genres"]]), ]
genres <- unique(genres)
genreRatings <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(genreRatings) <- c('genre', 'count', 'weight')

for(genre in genres$genres) {
  if(genre != ""){
    temp <- groupedGenre_complete[grepl(genre, groupedGenre_complete[["genres"]]), ]
    num <- length(temp$weightedRating)
    weight <- mean(temp$weightedRating)
    #print(c(genre, num, weight))
    genreRatings[nrow(genreRatings)+1,] = c(genre, num, weight)
  }
}
genreRatings
```

```{r}
# 2(B)
types <- unique(groupedGenre_complete$titleType)
genrewtype <- data.frame(matrix(ncol = 4, nrow = 0))
colnames(genrewtype) <- c('genre', 'type', 'count', 'weight')

for(genre in genres$genres) {
  if(genre != ""){
    temp <- groupedGenre_complete[grepl(genre, groupedGenre_complete[["genres"]]), ]
    for(type in types) {
      temp2 <- temp[grepl(type, temp[["titleType"]]), ]
      num <- length(temp2$weightedRating)
      weight <- mean(temp2$weightedRating)
      genrewtype[nrow(genrewtype)+1,] = c(genre, type, num, weight)
    }
  }
}
genrewtype <- genrewtype %>% 
  mutate(IsDrama = ifelse(genre == "Drama", "drama", "other"))
genrewtype
```


```{r}
# 2(C,D)
byGenre2 <- byGenre1[grepl("Drama", byGenre1[["genres"]]), ]
groupedGenre2 <- byGenre2 %>%
  group_by(titleType, genres) %>%
  summarize(weightedRating = sum(averageRating * numVotes) / sum(numVotes), totalVotes = sum(numVotes))

groupedGenre_complete2 <- na.omit(groupedGenre2)
groupedGenre_complete2
```

```{r}
# cleveland <- groupedGenre_complete2 %>% 
#   ungroup() %>%
#   group_by(titleType, genres) %>%
#   summarize(mean = mean(weightedRating))
# cleveland
```

<br/><br/>
Our transformations are as follows:
- First we filtered out all of the titles that were not created by experienced directors. The remaining titles were grouped by title type, and genre. A new column was added for weighted ratings (ratings weighted by number of votes) and total number of votes. Any potential rows with missing values were dropped.
- To see how different genres compare with each other, we first obtained all unique genres. Many of the rows in the genre column had comma separated values. However, there were some rows that had singular genre names. It can be noted that a list of all singular genre names represents the unique genre names. For each unique genre name, we obtained the total number of times the genre appears (within both singular and comma separated row values) and the average rating of all of the works within that genre. We also grouped this dataset based on title type to see what the distribution across title types looks like.
- Due to the large size of the data, it is difficult to view trends within each genre. Therefore, we decided to specifically look at the most popular genre. After visualizing the comparison of different genres (seen in Chapter 5.2), we concluded that the most popular genre is "Drama". Therefore, we subset our previous dataset of works by experienced directors by works that have "Drama" as at least one of the genre types. This was again grouped as earlier (grouped by title type, and genre, with the addition of total votes and weighted averages).


## Transformations to study the performance of different director-writer pairs
```{r}
#3(A)
df1 <- basics_ratings_crew[!is.na(basics_ratings_crew$writers),]
df1 <- df1[!is.na(df1$directors),]

df1$director_writer_pair <- paste(df1$directors,"-", df1$writers)
tt <- df1 %>% count(director_writer_pair, sort = TRUE)
ttt <- c(tt[1:10,1])
df2 <- subset(df1, director_writer_pair %in% ttt)

#3(B)
temp1 <- group_by(df1, director_writer_pair, titleType, genres)
temp2 <- summarise(temp1, totalVotes = sum(numVotes))
df3 <- summarise(temp1, weightedRating = sum(averageRating * numVotes) / sum(numVotes))

temp3 <- df3 %>% right_join(temp2, by=c("director_writer_pair","titleType", "genres"))

df3_filtered <- filter(temp3, weightedRating == 10)
new_df3_filter <- merge(df3_filtered, tt, by = 'director_writer_pair')
new_filter <- filter(new_df3_filter, n > 5)
```
<br/>The question basically addresses two problems<br/>
- The first part studies the top 10 director - writer pairs based on the number of times they worked together. Further, these pairs are used to study the distribution of average ratings of different title types they have produced.<br/>
- The second part studies that out of all the director writer pairs having average rating of 10, what is the distribution of the num of Votes for those particular pairs faceted by titleType. <br/>

<br/><br/>
For addressing the first question mentioned above we need to perform the following transformations:<br/>
- First, we filtered out the rows from the basics_ratings_crew dataset that had NA for writers and directors. We wanted to study the different director writer pairs so it was important that the dataset had no NULL values for either of these variables.<br/>
- Furthermore, for making the pair we used the paste function for concatenating the director column with writer column to form new column named director_writer_pair. This merging was required as our main aim revolves around studying the director-writer pair and this new columns will ease the upcoming visualization process.<br/>
- The total unique director writer pairs were approximately 600K. Visualizing all of them is not feasible and the results that they would give would also not be intuitive. Therefore, we decided to pick the top 10 pairs based on the number of times they have worked together. So we calculated the count of all the pairs and then selected the top 10. <br/> 
- Eventually, we filtered the original dataset with the top 10 director writer pairs.<br/>

<br/><br/>
For addressing the second question mentioned above we need to perform the following transformations:<br/>
- To begin with, we used the dataset created for the above question which contained the director writer pairs. Furthermore, we grouped the data by "director_writer_pair", "titleType", and "genres" and then summarized the data by calculating the total number of Votes received by the pair for different title types.<br/>
- Further, we summarized the same grouped data for calculating the weighted rating which is calculated by taking the sum of average rating $\times$ number of Votes divided by total number of Votes.<br/>
- Next, we joined both the grouped data to get the weighted rating as well as total number of Votes for a particular director-writer pair.<br/> 
- Finally, we filtered the data by weighted rating in order to get only the pairs having weighted rating equal to 10. We then merged this filtered data with the data having the count of number of times a particular pair worked together.<br/>
- The final dataset had total of 783 pairs who had average rating of 10 so to further filter the data we studied the distribution of the number of times the pair worked together and found that out of 783, 692 pairs worked with each other only once or twice and therefore we further narrowed the data to only consider the pairs who have worked more than 5 times with each other.<br/>

```{r}
tttt <- df1 %>%
    group_by(director_writer_pair) %>%
    summarise(weigthedRating = sum(averageRating * numVotes) / sum(numVotes))

t_final <- merge(tttt, tt, by = 'director_writer_pair')
t_final <- t_final[with(t_final, order(-n, -weigthedRating)), ]
```


```{r}
tttt <- df1 %>%
    group_by(director_writer_pair, directors, writers) %>%
    summarise(weightedRating = sum(averageRating * numVotes) / sum(numVotes))
tttt
t_final <- merge(tttt, tt, by = 'director_writer_pair')
t_final <- t_final[with(t_final, order(-n, -weightedRating)), ]
t_final
```

### Interactive Plot

```{r}
int_groupedGenre <- byGenre1 %>%
  group_by(titleType, genres, startYear) %>%
  summarize(weightedRating = sum(averageRating * numVotes) / sum(numVotes), totalVotes = sum(numVotes))

int_groupedGenre_complete <- na.omit(groupedGenre)
int_groupedGenre_complete

write.csv(int_groupedGenre,"sources_short/groupedGenres.csv", row.names = FALSE)
write.csv(int_groupedGenre_complete,"sources_short/groupedGenres_complete.csv", row.names = FALSE)
```


```{r}
for(type in unique(int_groupedGenre_complete$titleType)) {
  dRSub <- groupedGenre_complete[which(groupedGenre_complete$titleType == type), ]
  filename = paste0("sources_short/titletypes/",type,".csv")
  write.csv(dRSub, filename, row.names = FALSE)
}
```

The above transformation subsets our data by genre and saves each subset as its own file.

```{r}
# directorRatings <- df1 %>%
#      group_by(directors, startYear) %>%
#      summarise(weightedRating = sum(averageRating * numVotes) / sum(numVotes))
# directorRatings
# write.csv(directorRatings,"sources_short/directors/directorRatings.csv", row.names = FALSE)
```
